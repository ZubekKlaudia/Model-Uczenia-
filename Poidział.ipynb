{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMcqu6FnYQFhGyerZBtzHvf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZubekKlaudia/Model-Uczenia-/blob/main/Poidzia%C5%82.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q kaggle"
      ],
      "metadata": {
        "id": "ag3xbGHGqxmj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d jessicali9530/stanford-dogs-dataset --unzip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1YkbSK8Eq1SD",
        "outputId": "9734a26c-da9f-4bc7-b64c-58b3d139abf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/jessicali9530/stanford-dogs-dataset\n",
            "License(s): other\n",
            "Downloading stanford-dogs-dataset.zip to /content\n",
            "100% 748M/750M [00:26<00:00, 30.2MB/s]\n",
            "100% 750M/750M [00:26<00:00, 29.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "9LkZ4XvOrvwy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = './'\n",
        "input_dir = os.path.join(data_dir, './images/Images/')"
      ],
      "metadata": {
        "id": "fAPhptu8rmzD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aR-r9_aoqv4X",
        "outputId": "249d266f-9a86-400a-9c2b-53d36e77f25b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dane zostały podzielone na zbiory treningowy, walidacyjny i testowy.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Ustaw ścieżki\n",
        "train_dir = './data/train'\n",
        "val_dir = './data/val'\n",
        "test_dir = './data/test'\n",
        "\n",
        "# Utwórz katalogi na zbiory treningowy, walidacyjny i testowy\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "os.makedirs(val_dir, exist_ok=True)\n",
        "os.makedirs(test_dir, exist_ok=True)\n",
        "\n",
        "# Wczytaj wszystkie foldery klas (każdy folder to jedna rasa)\n",
        "classes = os.listdir(input_dir)\n",
        "\n",
        "# Ustaw proporcje podziału\n",
        "train_ratio = 0.7\n",
        "val_ratio = 0.15\n",
        "test_ratio = 0.15\n",
        "\n",
        "# Dla każdej klasy utwórz odpowiedni podział\n",
        "for class_name in classes:\n",
        "    # Pomijaj ukryte pliki, jeśli takie są (np. .DS_Store na macOS)\n",
        "    if class_name.startswith('.'):\n",
        "        continue\n",
        "\n",
        "    # Pobierz ścieżkę do folderu danej klasy\n",
        "    class_path = os.path.join(input_dir, class_name)\n",
        "\n",
        "    # Sprawdź, czy to faktycznie jest folder\n",
        "    if not os.path.isdir(class_path):\n",
        "        continue\n",
        "\n",
        "    # Pobierz wszystkie obrazy dla danej klasy\n",
        "    images = os.listdir(class_path)\n",
        "\n",
        "    # Podziel na zbiory\n",
        "    train_images, val_test_images = train_test_split(images, test_size=(1 - train_ratio))\n",
        "    val_images, test_images = train_test_split(val_test_images, test_size=(test_ratio / (val_ratio + test_ratio)))\n",
        "\n",
        "    # Utwórz katalogi dla danej klasy w zbiorach\n",
        "    os.makedirs(os.path.join(train_dir, class_name), exist_ok=True)\n",
        "    os.makedirs(os.path.join(val_dir, class_name), exist_ok=True)\n",
        "    os.makedirs(os.path.join(test_dir, class_name), exist_ok=True)\n",
        "\n",
        "    # Przenieś obrazy do odpowiednich katalogów\n",
        "    for image in train_images:\n",
        "        shutil.copy(os.path.join(class_path, image), os.path.join(train_dir, class_name, image))\n",
        "\n",
        "    for image in val_images:\n",
        "        shutil.copy(os.path.join(class_path, image), os.path.join(val_dir, class_name, image))\n",
        "\n",
        "    for image in test_images:\n",
        "        shutil.copy(os.path.join(class_path, image), os.path.join(test_dir, class_name, image))\n",
        "\n",
        "print(\"Dane zostały podzielone na zbiory treningowy, walidacyjny i testowy.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Liczenie liczby zdjęć w każdym z katalogów (treningowy, walidacyjny, testowy)\n",
        "train_images_count = sum([len(os.listdir(os.path.join(train_dir, class_name))) for class_name in os.listdir(train_dir)])\n",
        "val_images_count = sum([len(os.listdir(os.path.join(val_dir, class_name))) for class_name in os.listdir(val_dir)])\n",
        "test_images_count = sum([len(os.listdir(os.path.join(test_dir, class_name))) for class_name in os.listdir(test_dir)])\n",
        "\n",
        "# Wyświetlanie wyników\n",
        "print(\"Liczba zdjęć w katalogu treningowym: \", train_images_count)\n",
        "print(\"Liczba zdjęć w katalogu walidacyjnym: \", val_images_count)\n",
        "print(\"Liczba zdjęć w katalogu testowym: \", test_images_count)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ihoZBl3tWui",
        "outputId": "89c32d18-75c0-476f-9d70-d5406f4505ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Liczba zdjęć w katalogu treningowym:  14338\n",
            "Liczba zdjęć w katalogu walidacyjnym:  3097\n",
            "Liczba zdjęć w katalogu testowym:  3145\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Ścieżki do katalogów\n",
        "train_dir = './data/train'\n",
        "val_dir = './data/val'\n",
        "test_dir = './data/test'\n",
        "\n",
        "# Stworzenie generatorów\n",
        "# 1. Generator dla danych treningowych z augmentacją\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,  # Normalizacja pikseli do zakresu [0, 1]\n",
        "    rotation_range=40,  # Przypadkowe obracanie obrazów\n",
        "    width_shift_range=0.2,  # Przesunięcie obrazu w poziomie\n",
        "    height_shift_range=0.2,  # Przesunięcie obrazu w pionie\n",
        "    shear_range=0.2,  # Zniekształcenie obrazu\n",
        "    zoom_range=0.2,  # Powiększenie obrazu\n",
        "    horizontal_flip=True,  # Odbicie poziome\n",
        "    fill_mode='nearest'  # Wypełnianie nowych pikseli\n",
        ")\n",
        "\n",
        "# 2. Generator dla danych walidacyjnych i testowych (bez augmentacji)\n",
        "# Tylko normalizacja pikseli\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# 3. Tworzenie generatorów danych z katalogów\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,  # Katalog z danymi treningowymi\n",
        "    target_size=(150, 150),  # Rozmiar obrazu, do którego zostaną dopasowane wszystkie obrazy\n",
        "    batch_size=32,  # Liczba obrazów w jednej paczce\n",
        "    class_mode='categorical'  # Typ etykiety (wieloklasowa klasyfikacja)\n",
        ")\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    val_dir,  # Katalog z danymi walidacyjnymi\n",
        "    target_size=(150, 150),  # Rozmiar obrazu\n",
        "    batch_size=32,  # Liczba obrazów w jednej paczce\n",
        "    class_mode='categorical'  # Typ etykiety\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,  # Katalog z danymi testowymi\n",
        "    target_size=(150, 150),  # Rozmiar obrazu\n",
        "    batch_size=32,  # Liczba obrazów w jednej paczce\n",
        "    class_mode='categorical'  # Typ etykiety\n",
        ")\n",
        "\n",
        "# Opcjonalnie możesz sprawdzić pierwsze obrazy w generatorze\n",
        "for data_batch, labels_batch in train_generator:\n",
        "    print(data_batch.shape)  # Rozmiar paczki obrazów\n",
        "    print(labels_batch.shape)  # Rozmiar paczki etykiet\n",
        "    break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BU8JNy0MtkeR",
        "outputId": "fc6bca86-13d4-4f82-e59e-f91287c155d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 14338 images belonging to 120 classes.\n",
            "Found 3097 images belonging to 120 classes.\n",
            "Found 3145 images belonging to 120 classes.\n",
            "(32, 150, 150, 3)\n",
            "(32, 120)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n"
      ],
      "metadata": {
        "id": "RGKZL57VvpcO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Załaduj model ResNet50 bez wag, aby wykorzystać go jako bazę\n",
        "base_model = ResNet50(weights=None, include_top=False, input_shape=(150, 150, 3))\n",
        "\n",
        "# Dodajemy własne warstwy na końcu sieci\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)  # Global Average Pooling, aby zmniejszyć wymiary\n",
        "x = Dense(512, activation='relu')(x)  # Gęsta warstwa\n",
        "predictions = Dense(120, activation='softmax')(x)  # Ostateczna warstwa klasyfikacji (120 klas)\n",
        "\n",
        "# Tworzymy model\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# 2. Zamrożenie wszystkich warstw poza ostatnimi 10, aby dostroić model\n",
        "for layer in base_model.layers[:-10]:  # Zamrażamy wszystkie warstwy oprócz ostatnich 10\n",
        "    layer.trainable = False\n"
      ],
      "metadata": {
        "id": "rtbuCbtwvrVu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=Adam(learning_rate=0.0001),  # Używamy Adam jako optymalizator\n",
        "              loss='categorical_crossentropy',  # Funkcja straty do wieloklasowej klasyfikacji\n",
        "              metrics=['accuracy'])  # Metryka do oceny wyników\n"
      ],
      "metadata": {
        "id": "YJ5p3Blhvv2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_generator,  # Generator dla danych treningowych\n",
        "    steps_per_epoch=train_generator.samples // train_generator.batch_size,  # Liczba kroków na epokę\n",
        "    epochs=20,  # Liczba epok\n",
        "    validation_data=validation_generator,  # Generator dla danych walidacyjnych\n",
        "    validation_steps=validation_generator.samples // validation_generator.batch_size,  # Liczba kroków na epokę walidacyjną\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bf1WU9T8v2Wv",
        "outputId": "3f2bcf18-7bf2-43ab-ff12-da39cfe01f39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m 15/448\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20:48\u001b[0m 3s/step - accuracy: 0.0083 - loss: 4.7907"
          ]
        }
      ]
    }
  ]
}